{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross entropy reliability algorithm with openturns\n",
    "\n",
    "Source of the algorithm : J. Morio & M. Balesdent, Estimation of Rare Event Probabilities in Complex Aerospace and Other Systems, A Practical Approach, Elsevier, 2015\n",
    "\n",
    "\n",
    "The theory is given for a failure event defined as $\\phi(\\mathbf{X})>S$ with $\\mathbf{X}$ a random vector following a joint PDF $h_0$, $S$ a threshold and $\\phi$ a limit state function, without loss of generality.\n",
    "\n",
    "The IS probability estimate by Importance Sampling $\\widehat{P}^{IS}$ is given by \n",
    "\\begin{equation}\n",
    "\\widehat{P}^{IS}=\\frac{1}{N} \\sum_{i=1}^{N} {\\bf 1}_{\\phi(\\mathbf{X}_i)>S} \\frac{h_0(\\mathbf{X}_i)}{h(\\mathbf{X}_i)}.\n",
    "\\label{ISeq}\n",
    "\\end{equation}\n",
    "\n",
    "It is well-known that the optimal density minimizing the variance of the estimator $h_{opt}$ is  defined as\n",
    "\\begin{equation}\n",
    "h_{opt}=\\frac{{\\mathbf 1}_{\\phi(x)>S}h_0}{P}.\n",
    "\\label{opt}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "with $P$ the failure probability and is inaccessible in practice since this probability is unknown. \n",
    "\n",
    "Let us define $h_\\lambda$, a family of densities indexed by a parameter $\\lambda\\in \\Delta$ where $\\Delta$ is the multidimensional space of pdf parameters. The parameter $\\lambda$ is, for instance, the mean and the variance in the case of Gaussian densities. The objective of importance sampling with Cross-Entropy (CE) is to determine the parameter $\\lambda_{opt}$ that minimizes the Kullback-Leibler divergence between $h_{\\lambda_{opt}}$ and $h_{opt}$. The value of $\\lambda_{opt}$ is thus obtained as follows\n",
    "\\begin{equation}\n",
    "\\lambda_{opt}= \\underset{\\lambda}{\\operatorname{argmin}}\\left\\{ D(h_{opt},h_\\lambda) \\right\\},\n",
    "\\label{opti}\n",
    "\\end{equation}\n",
    "where $D$ is the Kullback-Leibler divergence defined between two densities $p$ and $q$ by \n",
    "\\begin{equation}\n",
    "D(q,p)=\\int_{\\mathbb{R}^d} q(x) \\ln(q(x))dx- \\int_{\\mathbb{R}^d} q(x) \\ln(p(x))dx.\n",
    "\\end{equation} \n",
    "\n",
    "Determining the parameter $\\lambda_{opt}$ is not obvious since it depends on the unknown pdf $h_{opt}$. In fact, it can be shown that it is equivalent to solve\n",
    "\\begin{equation}\n",
    "\\lambda_{opt}=\\underset{\\lambda}{\\operatorname{argmax}}\\left\\{  E\\left[{\\bf 1}_{\\phi(\\mathbf{X})>S} \\ln \\left(h_\\lambda(\\mathbf{X}) \\right)\\right] \\right\\},\n",
    "\\label{CE1}\n",
    "\\end{equation}\n",
    "where $E$ defines the expectation operator. In fact, one does not focus directly on the preceding equation  but proceeds iteratively to estimate $\\lambda_{opt}$ with an iterative sequence of thresholds,\n",
    "\\begin{equation}\n",
    "\\gamma_0<\\gamma_1 < \\gamma_2 < ... <\\gamma_k<...\\leq S,\n",
    "\\end{equation}\n",
    "chosen adaptively using quantile definition. At iteration $k$, the value $\\lambda_{k-1}$ is available and one maximizes in practice\n",
    "\\begin{equation}\n",
    "\\lambda_k=\\underset{\\lambda}{\\operatorname{argmax}} \\frac{1}{N} \\sum_{i=1}^N {\\bf 1}_{\\phi(\\mathbf{X}_i)>\\gamma_k} \\frac{h_0(\\mathbf{X}_i)}{h_{\\lambda_{k-1}}(\\mathbf{X}_i)} \\ln (h_{\\lambda}(\\mathbf{X}_i)).\n",
    "\\end{equation}\n",
    "where the samples $\\mathbf{X}_1,...,\\mathbf{X}_N$ are generated with $h_{\\lambda_{k-1}}$.\n",
    "The probability $\\widehat{P}^{CE}$ is then estimated with importance sampling at the last iteration. The Cross-Entropy optimization algorithm for importance sampling density is\n",
    "\n",
    "\n",
    "\n",
    "1. $k=1$, define $h_{\\lambda_0}=h_0$ and set $\\rho \\in [0,1]$\n",
    "2. Generate the population $\\mathbf{X}_1,\\cdots,\\mathbf{X}_N$ according to the pdf $h_{\\lambda_{k-1}}$ and apply the function $\\phi$ in order to have $Y_1=\\phi(\\mathbf{X}_1),\\ldots,Y_N=\\phi(\\mathbf{X}_N)$\n",
    "3. Compute the empirical $\\rho$-quantile $q_k=\\min(S, Y_{\\left\\lfloor\\rho N\\right\\rfloor})$, where $\\lfloor a\\rfloor$ denotes the largest integer that is smaller than or equal to $a$\n",
    "4. Optimize the parameters of the auxiliary pdf family as $\\lambda_k=\\underset{\\lambda}{\\operatorname{argmax}}\\left\\{\\frac{1}{N}\\displaystyle \\sum_{i=1}^N\\left[1_{\\phi(\\mathbf{X}_i)>q_k} \\frac{h_0(\\mathbf{X}_i)}{h_{\\lambda_{k-1}}(\\mathbf{X}_i)}ln\\left[h_\\lambda(\\mathbf{X}_i)\\right]\\right]\\right\\}$\n",
    "5. If $q_k<S$, $k\\leftarrow k+1$, go to Step 2\n",
    "6. Estimate the probability $\\widehat{P}^{CE}(\\phi(\\mathbf{\\mathbf{X}}>S))=\\frac{1}{N}\\displaystyle \\sum_{i=1}^{N} 1_{\\phi(\\mathbf{X}_i)>S} \\frac{h_0(\\mathbf{X}_i)}{h_{\\lambda_k-1}(\\mathbf{X}_i)}$\n",
    "\n",
    "\n",
    "This algorithm is implemented in the following class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openturns as ot\n",
    "import math as m\n",
    "from  CrossEntropyAlgorithm import CrossEntropyAlgorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical experiments\n",
    "\n",
    "http://openturns.github.io/openturns/master/examples/reliability_sensitivity/estimate_probability_monte_carlo.html\n",
    "\n",
    "\n",
    "We consider a simple beam stressed by a traction load F at both sides.\n",
    "\n",
    "The geometry is supposed to be deterministic; the diameter D is equal to:\n",
    "\n",
    "$D=0.02 \\textrm{ (m)}.$\n",
    "\n",
    "By definition, the yield stress is the load divided by the surface. Since the surface is \\pi D^2/4, the stress is:\n",
    "\n",
    "$S = \\frac{F}{\\pi D^2/4}.$\n",
    "\n",
    "Failure occurs when the beam plastifies, i.e. when the axial stress gets larger than the yield stress:\n",
    "\n",
    "$R - \\frac{F}{\\pi D^2/4} \\leq 0$\n",
    "\n",
    "where R is the strength.\n",
    "\n",
    "Therefore, the limit state function G is:\n",
    "\n",
    "$G(R,F) = R - \\frac{F}{\\pi D^2/4},$\n",
    "\n",
    "for any R,F\\in\\mathbb{R}.\n",
    "\n",
    "The value of the parameter D is such that:\n",
    "\n",
    "$D^2/4 = 10^{-4},$\n",
    "\n",
    "which leads to the equation:\n",
    "\n",
    "$G(R,F) = R - \\frac{F}{10^{-4} \\pi}.$\n",
    "\n",
    "with\n",
    "\n",
    "$R \\sim LogNormal(\\mu_R=3\\times 10^6, \\sigma_R=3\\times 10^5) [Pa]$\n",
    "\n",
    "$F \\sim Normal(\\mu_F=750, \\sigma_F=50) [N]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation of the event\n",
    "distribution_R = ot.LogNormalMuSigma(300.0, 30.0, 0.0).getDistribution()\n",
    "distribution_F = ot.Normal(75e3, 5e3)\n",
    "marginals = [distribution_R, distribution_F]\n",
    "distribution = ot.ComposedDistribution(marginals)\n",
    "\n",
    "# create the model\n",
    "model = ot.SymbolicFunction(['R', 'F'], ['R-F/(pi_*100.0)'])\n",
    "\n",
    "#create the event \n",
    "vect = ot.RandomVector(distribution)\n",
    "G = ot.CompositeRandomVector(model, vect)\n",
    "event = ot.ThresholdEvent(G, ot.Less(), 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determination of reference probability\n",
    "#MonteCarlo experiment\n",
    "n_MC = 1e6\n",
    "\n",
    "# create a Monte Carlo algorithm\n",
    "experiment = ot.MonteCarloExperiment()\n",
    "algo = ot.ProbabilitySimulationAlgorithm(event, experiment)\n",
    "algo.setMaximumOuterSampling(int(n_MC))\n",
    "algo.setMaximumCoefficientOfVariation(0.01)\n",
    "algo.run()\n",
    "# retrieve results\n",
    "result = algo.getResult()\n",
    "probability = result.getProbabilityEstimate()\n",
    "print('Pf=', probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters of the distribution  (warning : native parameters)\n",
    "distribution.getParameter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross entropy estimation with full parameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters of the algorithm\n",
    "n_IS= 2500 # Number of samples at each iteration\n",
    "rho_quantile= 25 # Quantile determining the percentage of failure samples in the current population \n",
    "\n",
    "\n",
    "## Definition of auxiliary distribution\n",
    "distribution_margin1 = ot.LogNormalMuSigma(300.0, 30.0, 0.0).getDistribution()\n",
    "distribution_margin2 = ot.Normal(75e3, 5e3)\n",
    "aux_marginals = [distribution_margin1, distribution_margin2]\n",
    "aux_distribution = ot.ComposedDistribution(aux_marginals)\n",
    "\n",
    "\n",
    "## Definition of parameters to be optimized\n",
    "active_parameters = [True,True,True,True,True] # active parameters from the auxiliary distribution which will be optimized\n",
    "### WARNING : native parameters of distribution have to be considered\n",
    "\n",
    "\n",
    "bounds = ot.Interval([3,0.09,0.,50e3,2e3], # bounds on the active parameters\n",
    "                     [7,0.5,0.5,100e3,10e3])\n",
    "\n",
    "initial_theta= [5.70,0.1,0.,75e3,5e3] # initial value of the active parameters\n",
    "\n",
    "verbose = True # verbosity parameter, if true, the values of auxiliary parameters and the current threshold will be displayed\n",
    "\n",
    "## Definition of the algorithm\n",
    "CE_1 = CrossEntropyAlgorithm(event,n_IS,rho_quantile,distribution,active_parameters,bounds,initial_theta,verbose)\n",
    "\n",
    "# Run of the algorithm\n",
    "CE_1.compute_proba()\n",
    "print('Probability of failure:',CE_1.getFailureProbability())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Found optimal auxiliary density\n",
    "CE_1.getaux_density()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross entropy estimation with partial parameter optimization (only the means of the margins, all the others as considered as their reference values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters of the algorithm\n",
    "n_IS= 2500 # Number of samples at each iteration\n",
    "rho_quantile= 25 # Quantile determining the percentage of failure samples in the current population \n",
    "\n",
    "\n",
    "## Definition of auxiliary distribution\n",
    "distribution_margin1 = ot.LogNormalMuSigma(300.0, 30.0, 0.0).getDistribution()\n",
    "distribution_margin2 = ot.Normal(75e3, 5e3)\n",
    "aux_marginals = [distribution_margin1, distribution_margin2]\n",
    "aux_distribution = ot.ComposedDistribution(aux_marginals)\n",
    "\n",
    "\n",
    "## Definition of parameters to be optimized\n",
    "active_parameters = [True,False,False,True,False] # active parameters from the auxiliary distribution which will be optimized\n",
    "### WARNING : native parameters of distribution have to be considered\n",
    "bounds =  ot.Interval([3,50e3], # bounds on the active parameters\n",
    "                       [7,100e3])\n",
    "\n",
    "initial_theta= [5.70,75e3] # initial value of the active parameters\n",
    "\n",
    "verbose = True# verbosity parameter, if true, the values of auxiliary parameters and the current threshold will be displayed\n",
    "\n",
    "## Definition of the algorithm\n",
    "CE_2 = CrossEntropyAlgorithm(event,n_IS,rho_quantile,distribution,active_parameters,bounds,initial_theta,verbose)\n",
    "\n",
    "# Run of the algorithm\n",
    "CE_2.compute_proba()\n",
    "print('Probability of failure:',CE_2.getFailureProbability())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Found optimal auxiliary density\n",
    "CE_2.getaux_density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
