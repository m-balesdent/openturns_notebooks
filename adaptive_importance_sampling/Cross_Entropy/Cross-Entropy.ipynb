{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross entropy reliability algorithm with openturns\n",
    "\n",
    "Source of the algorithm : J. Morio & M. Balesdent, Estimation of Rare Event Probabilities in Complex Aerospace and Other Systems, A Practical Approach, Elsevier, 2015\n",
    "\n",
    "\n",
    "The theory is given for a failure event defined as $\\phi(\\mathbf{X})>S$ with $\\mathbf{X}$ a random vector following a joint PDF $h_0$, $S$ a threshold and $\\phi$ a limit state function, without loss of generality.\n",
    "\n",
    "The IS probability estimate by Importance Sampling $\\widehat{P}^{IS}$ is given by \n",
    "\\begin{equation}\n",
    "\\widehat{P}^{IS}=\\frac{1}{N} \\sum_{i=1}^{N} {\\bf 1}_{\\phi(\\mathbf{X}_i)>S} \\frac{h_0(\\mathbf{X}_i)}{h(\\mathbf{X}_i)}.\n",
    "\\label{ISeq}\n",
    "\\end{equation}\n",
    "\n",
    "It is well-known that the optimal density minimizing the variance of the estimator $h_{opt}$ is  defined as\n",
    "\\begin{equation}\n",
    "h_{opt}=\\frac{{\\mathbf 1}_{\\phi(x)>S}h_0}{P}.\n",
    "\\label{opt}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "with $P$ the failure probability and is inaccessible in practice since this probability is unknown. \n",
    "\n",
    "Let us define $h_\\lambda$, a family of densities indexed by a parameter $\\lambda\\in \\Delta$ where $\\Delta$ is the multidimensional space of pdf parameters. The parameter $\\lambda$ is, for instance, the mean and the variance in the case of Gaussian densities. The objective of importance sampling with Cross-Entropy (CE) is to determine the parameter $\\lambda_{opt}$ that minimizes the Kullback-Leibler divergence between $h_{\\lambda_{opt}}$ and $h_{opt}$. The value of $\\lambda_{opt}$ is thus obtained as follows\n",
    "\\begin{equation}\n",
    "\\lambda_{opt}= \\underset{\\lambda}{\\operatorname{argmin}}\\left\\{ D(h_{opt},h_\\lambda) \\right\\},\n",
    "\\label{opti}\n",
    "\\end{equation}\n",
    "where $D$ is the Kullback-Leibler divergence defined between two densities $p$ and $q$ by \n",
    "\\begin{equation}\n",
    "D(q,p)=\\int_{\\mathbb{R}^d} q(x) \\ln(q(x))dx- \\int_{\\mathbb{R}^d} q(x) \\ln(p(x))dx.\n",
    "\\end{equation} \n",
    "\n",
    "Determining the parameter $\\lambda_{opt}$ is not obvious since it depends on the unknown pdf $h_{opt}$. In fact, it can be shown that it is equivalent to solve\n",
    "\\begin{equation}\n",
    "\\lambda_{opt}=\\underset{\\lambda}{\\operatorname{argmax}}\\left\\{  E\\left[{\\bf 1}_{\\phi(\\mathbf{X})>S} \\ln \\left(h_\\lambda(\\mathbf{X}) \\right)\\right] \\right\\},\n",
    "\\label{CE1}\n",
    "\\end{equation}\n",
    "where $E$ defines the expectation operator. In fact, one does not focus directly on the preceding equation  but proceeds iteratively to estimate $\\lambda_{opt}$ with an iterative sequence of thresholds,\n",
    "\\begin{equation}\n",
    "\\gamma_0<\\gamma_1 < \\gamma_2 < ... <\\gamma_k<...\\leq S,\n",
    "\\end{equation}\n",
    "chosen adaptively using quantile definition. At iteration $k$, the value $\\lambda_{k-1}$ is available and one maximizes in practice\n",
    "\\begin{equation}\n",
    "\\lambda_k=\\underset{\\lambda}{\\operatorname{argmax}} \\frac{1}{N} \\sum_{i=1}^N {\\bf 1}_{\\phi(\\mathbf{X}_i)>\\gamma_k} \\frac{h_0(\\mathbf{X}_i)}{h_{\\lambda_{k-1}}(\\mathbf{X}_i)} \\ln (h_{\\lambda}(\\mathbf{X}_i)).\n",
    "\\end{equation}\n",
    "where the samples $\\mathbf{X}_1,...,\\mathbf{X}_N$ are generated with $h_{\\lambda_{k-1}}$.\n",
    "The probability $\\widehat{P}^{CE}$ is then estimated with importance sampling at the last iteration. The Cross-Entropy optimization algorithm for importance sampling density is\n",
    "\n",
    "\n",
    "\n",
    "1. $k=1$, define $h_{\\lambda_0}=h_0$ and set $\\rho \\in [0,1]$\n",
    "2. Generate the population $\\mathbf{X}_1,\\cdots,\\mathbf{X}_N$ according to the pdf $h_{\\lambda_{k-1}}$ and apply the function $\\phi$ in order to have $Y_1=\\phi(\\mathbf{X}_1),\\ldots,Y_N=\\phi(\\mathbf{X}_N)$\n",
    "3. Compute the empirical $\\rho$-quantile $q_k=\\min(S, Y_{\\left\\lfloor\\rho N\\right\\rfloor})$, where $\\lfloor a\\rfloor$ denotes the largest integer that is smaller than or equal to $a$\n",
    "4. Optimize the parameters of the auxiliary pdf family as $\\lambda_k=\\underset{\\lambda}{\\operatorname{argmax}}\\left\\{\\frac{1}{N}\\displaystyle \\sum_{i=1}^N\\left[1_{\\phi(\\mathbf{X}_i)>q_k} \\frac{h_0(\\mathbf{X}_i)}{h_{\\lambda_{k-1}}(\\mathbf{X}_i)}ln\\left[h_\\lambda(\\mathbf{X}_i)\\right]\\right]\\right\\}$\n",
    "5. If $q_k<S$, $k\\leftarrow k+1$, go to Step 2\n",
    "6. Estimate the probability $\\widehat{P}^{CE}(\\phi(\\mathbf{\\mathbf{X}}>S))=\\frac{1}{N}\\displaystyle \\sum_{i=1}^{N} 1_{\\phi(\\mathbf{X}_i)>S} \\frac{h_0(\\mathbf{X}_i)}{h_{\\lambda_k-1}(\\mathbf{X}_i)}$\n",
    "\n",
    "\n",
    "This algorithm is implemented in the following class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openturns as ot\n",
    "import math as m\n",
    "from  CrossEntropyAlgorithm import CrossEntropyAlgorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical experiments\n",
    "\n",
    "http://openturns.github.io/openturns/master/examples/reliability_sensitivity/estimate_probability_monte_carlo.html\n",
    "\n",
    "\n",
    "We consider a simple beam stressed by a traction load F at both sides.\n",
    "\n",
    "The geometry is supposed to be deterministic; the diameter D is equal to:\n",
    "\n",
    "$D=0.02 \\textrm{ (m)}.$\n",
    "\n",
    "By definition, the yield stress is the load divided by the surface. Since the surface is \\pi D^2/4, the stress is:\n",
    "\n",
    "$S = \\frac{F}{\\pi D^2/4}.$\n",
    "\n",
    "Failure occurs when the beam plastifies, i.e. when the axial stress gets larger than the yield stress:\n",
    "\n",
    "$R - \\frac{F}{\\pi D^2/4} \\leq 0$\n",
    "\n",
    "where R is the strength.\n",
    "\n",
    "Therefore, the limit state function G is:\n",
    "\n",
    "$G(R,F) = R - \\frac{F}{\\pi D^2/4},$\n",
    "\n",
    "for any R,F\\in\\mathbb{R}.\n",
    "\n",
    "The value of the parameter D is such that:\n",
    "\n",
    "$D^2/4 = 10^{-4},$\n",
    "\n",
    "which leads to the equation:\n",
    "\n",
    "$G(R,F) = R - \\frac{F}{10^{-4} \\pi}.$\n",
    "\n",
    "with\n",
    "\n",
    "$R \\sim LogNormal(\\mu_R=3\\times 10^6, \\sigma_R=3\\times 10^5) [Pa]$\n",
    "\n",
    "$F \\sim Normal(\\mu_F=750, \\sigma_F=50) [N]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation of the event\n",
    "distribution_R = ot.LogNormalMuSigma(300.0, 30.0, 0.0).getDistribution()\n",
    "distribution_F = ot.Normal(75e3, 5e3)\n",
    "marginals = [distribution_R, distribution_F]\n",
    "distribution = ot.ComposedDistribution(marginals)\n",
    "\n",
    "# create the model\n",
    "model = ot.SymbolicFunction(['R', 'F'], ['R-F/(pi_*100.0)'])\n",
    "\n",
    "#create the event \n",
    "vect = ot.RandomVector(distribution)\n",
    "G = ot.CompositeRandomVector(model, vect)\n",
    "event = ot.ThresholdEvent(G, ot.Less(), 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pf= 0.0294834174762001\n"
     ]
    }
   ],
   "source": [
    "#Determination of reference probability\n",
    "#MonteCarlo experiment\n",
    "n_MC = 1e6\n",
    "\n",
    "# create a Monte Carlo algorithm\n",
    "experiment = ot.MonteCarloExperiment()\n",
    "algo = ot.ProbabilitySimulationAlgorithm(event, experiment)\n",
    "algo.setMaximumOuterSampling(int(n_MC))\n",
    "algo.setMaximumCoefficientOfVariation(0.01)\n",
    "algo.run()\n",
    "# retrieve results\n",
    "result = algo.getResult()\n",
    "probability = result.getProbabilityEstimate()\n",
    "print('Pf=', probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>[5.69881,0.0997513,0,75000,5000]</p>"
      ],
      "text/plain": [
       "class=Point name=Unnamed dimension=5 values=[5.69881,0.0997513,0,75000,5000]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters of the distribution  (warning : native parameters)\n",
    "distribution.getParameter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross entropy estimation with full parameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta | current threshold\n",
      "[5.5036,0.09,0.5,77770.2,9836.89] | 38.172025248957866\n",
      "[5.65353,0.424957,0.00964724,83470.6,9932.45] | -25.36969524711087\n",
      "0.029083411611290275\n",
      "Probability of failure: 0.029083411611290275\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters of the algorithm\n",
    "n_IS= 2500 # Number of samples at each iteration\n",
    "rho_quantile= 25 # Quantile determining the percentage of failure samples in the current population \n",
    "\n",
    "\n",
    "## Definition of auxiliary distribution\n",
    "distribution_margin1 = ot.LogNormalMuSigma(300.0, 30.0, 0.0).getDistribution()\n",
    "distribution_margin2 = ot.Normal(75e3, 5e3)\n",
    "aux_marginals = [distribution_margin1, distribution_margin2]\n",
    "aux_distribution = ot.ComposedDistribution(aux_marginals)\n",
    "\n",
    "\n",
    "## Definition of parameters to be optimized\n",
    "active_parameters = [True,True,True,True,True] # active parameters from the auxiliary distribution which will be optimized\n",
    "### WARNING : native parameters of distribution have to be considered\n",
    "\n",
    "\n",
    "bounds = ot.Interval([3,0.09,0.,50e3,2e3], # bounds on the active parameters\n",
    "                     [7,0.5,0.5,100e3,10e3])\n",
    "\n",
    "initial_theta= [5.70,0.1,0.,75e3,5e3] # initial value of the active parameters\n",
    "\n",
    "verbose = True # verbosity parameter, if true, the values of auxiliary parameters and the current threshold will be displayed\n",
    "\n",
    "## Definition of the algorithm\n",
    "CE_1 = CrossEntropyAlgorithm(event,n_IS,rho_quantile,distribution,active_parameters,bounds,initial_theta,verbose)\n",
    "\n",
    "# Run of the algorithm\n",
    "CE_1.run()\n",
    "CE_1results = CE_1.getResult()\n",
    "print('Probability of failure:',CE_1results.getProbabilityEstimate())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>ComposedDistribution(LogNormal(muLog = 5.5036, sigmaLog = 0.09, gamma = 0.5), Normal(mu = 77770.2, sigma = 9836.89), IndependentCopula(dimension = 2))</p>"
      ],
      "text/plain": [
       "class=ComposedDistribution name=ComposedDistribution dimension=2 copula=class=IndependentCopula name=IndependentCopula dimension=2 marginal[0]=class=LogNormal name=LogNormal dimension=1 muLog=5.5036 sigmaLog=0.09 gamma=0.5 marginal[1]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[77770.2] sigma=class=Point name=Unnamed dimension=1 values=[9836.89] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Found optimal auxiliary density\n",
    "CE_1results.getAuxiliaryDensity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross entropy estimation with partial parameter optimization (only the means of the margins, all the others as considered as their reference values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta | current threshold\n",
      "[5.72496,77893.1] | 38.38778597614599\n",
      "[5.71295,81827.3] | 37.88114215855242\n",
      "[5.71295,81827.3] | 21.22861007913673\n",
      "[5.71295,81827.3] | 20.331365412610083\n",
      "[5.71295,81827.3] | 20.205546550169544\n",
      "[5.68248,80810.4] | 18.450586562334266\n",
      "[5.47146,78067.9] | 16.239282906539742\n",
      "[5.41648,79684.4] | -28.94654371748183\n",
      "0.030238614762599675\n",
      "Probability of failure: 0.030238614762599675\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters of the algorithm\n",
    "n_IS= 2500 # Number of samples at each iteration\n",
    "rho_quantile= 25 # Quantile determining the percentage of failure samples in the current population \n",
    "\n",
    "\n",
    "## Definition of auxiliary distribution\n",
    "distribution_margin1 = ot.LogNormalMuSigma(300.0, 30.0, 0.0).getDistribution()\n",
    "distribution_margin2 = ot.Normal(75e3, 5e3)\n",
    "aux_marginals = [distribution_margin1, distribution_margin2]\n",
    "aux_distribution = ot.ComposedDistribution(aux_marginals)\n",
    "\n",
    "\n",
    "## Definition of parameters to be optimized\n",
    "active_parameters = [True,False,False,True,False] # active parameters from the auxiliary distribution which will be optimized\n",
    "### WARNING : native parameters of distribution have to be considered\n",
    "bounds =  ot.Interval([3,50e3], # bounds on the active parameters\n",
    "                       [7,100e3])\n",
    "\n",
    "initial_theta= [5.70,75e3] # initial value of the active parameters\n",
    "\n",
    "verbose = True# verbosity parameter, if true, the values of auxiliary parameters and the current threshold will be displayed\n",
    "\n",
    "## Definition of the algorithm\n",
    "CE_2 = CrossEntropyAlgorithm(event,n_IS,rho_quantile,distribution,active_parameters,bounds,initial_theta,verbose)\n",
    "\n",
    "# Run of the algorithm\n",
    "CE_2.run()\n",
    "CE_2results = CE_2.getResult()\n",
    "print('Probability of failure:',CE_2results.getProbabilityEstimate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>ComposedDistribution(LogNormal(muLog = 5.47146, sigmaLog = 0.0997513, gamma = 0), Normal(mu = 78067.9, sigma = 5000), IndependentCopula(dimension = 2))</p>"
      ],
      "text/plain": [
       "class=ComposedDistribution name=ComposedDistribution dimension=2 copula=class=IndependentCopula name=IndependentCopula dimension=2 marginal[0]=class=LogNormal name=LogNormal dimension=1 muLog=5.47146 sigmaLog=0.0997513 gamma=0 marginal[1]=class=Normal name=Normal dimension=1 mean=class=Point name=Unnamed dimension=1 values=[78067.9] sigma=class=Point name=Unnamed dimension=1 values=[5000] correlationMatrix=class=CorrelationMatrix dimension=1 implementation=class=MatrixImplementation name=Unnamed rows=1 columns=1 values=[1]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Found optimal auxiliary density\n",
    "CE_2results.getAuxiliaryDensity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<TABLE><TR><TD></TD><TH>X0</TH><TH>X1</TH></TR>\n",
       "<TR><TH>0</TH><TD>276.3637</TD><TD>79138.25</TD></TR>\n",
       "<TR><TH>1</TH><TD>205.1926</TD><TD>77774.93</TD></TR>\n",
       "<TR><TH>2</TH><TD>238.9636</TD><TD>85730.55</TD></TR>\n",
       "<TR><TD COLSPAN=\"3\">...</TD></TR>\n",
       "<TR><TH>2497</TH><TD>232.1639</TD><TD>75258.22</TD></TR>\n",
       "<TR><TH>2498</TH><TD>236.9963</TD><TD>81390.1</TD></TR>\n",
       "<TR><TH>2499</TH><TD>222.4556</TD><TD>75988.63</TD></TR>\n",
       "</TABLE>"
      ],
      "text/plain": [
       "class=Sample name=ComposedDistribution implementation=class=SampleImplementation name=ComposedDistribution size=2500 dimension=2 description=[X0,X1] data=[[276.364,79138.3],[205.193,77774.9],[238.964,85730.5],...,[232.164,75258.2],[236.996,81390.1],[222.456,75988.6]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Found CE Samples at the last iteration\n",
    "CE_2results.getSamples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
